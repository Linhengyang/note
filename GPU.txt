processing unit 的基本组成：
1. Control 控制单元。处理分枝、控制、判断等操作
2. ALU 算术单元，执行具体的运算
3. Cache 高速缓存，寄存器，存储一些非常即时的结果
4. DRAM 内存，存储一些次即时的结果


CPU：
    1. 非常大的 Control，配对以非常大的 Cache 单元，对 branching 的支持非常好。二者组合的数量不多
    2. ALU 不多

GPU:
    1. 小的 Control，配对以 小的 Cache 单元，对 branching 的支持少很多。二者组合的数量很多
    2. 为每个 Control/Cache 组合，配以很多 ALU。故总 ALU 数量非常多



考虑经典的 单一 execute unit（物理核心），多线程 的计算模型。单一物理核心意味着只能 并发 cocurrent，没办法 并行 parallel

什么是并发 cocurrent ？同一个物理实体上的多个事件，在（较短的）同一时间段先后发生（逻辑上的同时发生，物理上的先后运行，比如一个人同时吃三个馒头）。
并发的任务一定是互相抢占计算资源的。
什么是并行 parallel ？多个物理实体上的多个事件，在（瞬间）同一时间点真正同时发生（逻辑上和物理上都同时发生，比如三个人同时吃三个馒头）。
并行的任务之间的计算资源是互不干扰的。


（什么是线程？一个配有上下文环境的函数/任务，它可以被 execute unit 执行，也可以被挂起 stalled 等待执行。
    执行线程的意思就是 先提取线程上下文环境/从内存中读取data/IO 等准备工作，再运行线程编译好的逻辑。）

即 线程执行 = latency 提取上下文/等待数据/同步等待其他线程释放 execute unit锁/IO等所有非run运行的时间  +  runtime 逻辑（指令）
   线程总时间 = 延迟时间 latency + 运行时间 runtime
   一个线程执行，延迟 latency 和 运行 runtime 会多次交替发生，并不是只有一次的。



并发（多线程）是刚需
要在 单 execute unit上 实现并发（多线程），就必须要切换 线程。切换线程的意思，就是"物理核心腾出计算资源，停止执行当前线程，转而去执行另一个线程"
本文讲述的是，CPU 和 GPU 如何优化 单execute unit，并发（多线程）任务 之间的资源分配。

有以下两个原则限制：
原则一：物理核心切换线程，也意味着 物理核心的上下文环境也被切换。
原则二：一个时间瞬间，物理核心只能运行 run 一个线程的逻辑指令。但是物理核心不参与也不关心 线程的 latency 在干什么。

所以有了两个优化方向：
    1 实打实减少 单个线程的 latency，串行 执行线程。一个线程执行到实在无法继续（比如 OS 调度、等待很耗时的输入之类的），才让出计算资源，切换上下文以执行next线程
      减少 单线程 latency 需要很多工作，导致上下文切换的代价高负担重，所以正好尽量不 切换线程 
    2 接受单线程的 latency，承认单线程的 latency 难以优化，正在执行的 线程一旦进入 latency，物理核心马上让出，计算资源切换到 next可 run 运行的 线程上，以隐藏延迟 latency 
      需要有一个 同步锁，正在 物理核心上 run 运行的线程，会获得这个同步锁，结束 run 运行会释放这个同步锁。其他线程，即使 latency 结束了，也要等待 锁释放，才能获得计算资源以 run
      需要频繁切换线程（一遇到latency，物理核心就切换到可运行 run 的线程上，不浪费一丝计算资源），故上下文切换的代价必须小、轻量。



经典CPU模型（单物理核心、无超线程）：线程执行 以 时间片轮转 的方式切换，以实现 并发（多线程）

CPU 的优化方向，
是让在执行中的单个线程尽快完成任务，即“最小化每个线程的延迟”。遇到实在避不开的 停顿 了，才被动切换线程。
优化latency的技术非常复杂，最重要的就是降低读取数据的耗时，还有其他比如指令延迟、IO延迟、流水线延迟等，都有相应技术去优化。

CPU采取下述手段以优化：
1. 大容量 Cache（存储最近访问的data，尽量不从慢速内存读取数据）       2.复杂的控制逻辑（预测数据需求，乱序执行指令，分支预测等）
带来的代价：
1. 线程切换的成本很高、负担很重（上下文很大，比如完整的寄存器、堆栈等），所以不能频繁切换，所以也导致超线程的数量很少（基本只有2个）。后面会介绍超线程。
适合的任务：串行、依赖性强的任务





经典GPU模型（单物理核心、大量线程并发）：线程执行 以 当前线程一遇到latency马上切换next可run线程 的方式切换，以实现 并发（多线程）

GPU 的优化方向，
跟CPU不同的是，GPU的任务一般涉及大量数据（需要读取），故latency是无法可观缩小的，必须承认latency的存在。GPU 的优化方向，是是尽可能有效地切换线程，
遇到latency就尽量腾出计算资源切换到可run线程上，即“隐藏每个线程的延迟（跑其他线程去了）”。一遇到 latency 马上主动切换线程。
由于待执行的线程数量极大，有成千上万个，所以就没有避不开的停顿，所以物理核心始终在运行，计算资源利用率非常高。

GPU采取下述手段以优化： 
1. 轻量级的线程（上下文切换的消耗非常小，上下文就是简化的寄存器，不需要上下文保存/恢复机制，支持高频切换）     2. 单个物理核心可支持的线程数量非常庞大
适合的任务：大规模并行（物理上是并发，本质是说吞吐量高）、独立性强的任务




超线程CPU模型（单物理核心、一般2个逻辑线程（也叫逻辑核心））：超线程的设计哲学，和 GPU并发线程 是类似的，即切换next可run线程以隐藏latency。
不过，超线程只是 CPU 模型提高物理核心利用率的辅助手段，其线程依然是重量级线程、上下文依然很大，而且还引入了 锁竞争，所以超线程不会太频繁，不然会降低性能。
