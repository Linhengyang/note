processing unit 的基本组成：
1. Control 控制单元。处理分枝、控制、判断等操作
2. ALU 算术单元，执行具体的运算
3. Cache 高速缓存，寄存器，存储一些非常即时的结果
4. DRAM 内存，存储一些次即时的结果


CPU：
    1. 非常大的 Control，配对以非常大的 Cache 单元，对 branching 的支持非常好。二者组合的数量不多
    2. ALU 不多

GPU:
    1. 小的 Control，配对以 小的 Cache 单元，对 branching 的支持少很多。二者组合的数量很多
    2. 为每个 Control/Cache 组合，配以很多 ALU。故总 ALU 数量非常多



考虑经典的 单一 execute unit，多线程 的计算模型。
（什么是线程？一个配有上下文环境的函数/任务，它可以被 execute unit 执行，也可以被挂起 stalled 等待执行。
    执行线程的意思就是 先提取线程上下文环境/从内存中读取data/IO 等准备工作，再运行线程编译好的逻辑。）

即 线程执行 = latency 提取上下文/等待数据/同步等待其他线程释放 execute unit锁/IO等所有非run运行的时间  +  run 逻辑（指令）
   线程总时间 = 延迟时间 latency + 运行时间 runtime


单线程模型#TODO


切换线程以实现多线程：
原则一：多个线程之间可以切换线程，以运行不同的逻辑。不过这意味着上下文环境也被切换。
原则二：一个时间瞬间只能运行 run 一个逻辑。


CPU 的优化方向，是让在执行中的单个线程尽快完成任务，即“最小化每个线程的延迟”。
这需要优化的是 读取上下文环境（存储的数据）要快，因为 execute unit 会等待这个时间（延迟）。 CPU采取下述手段以优化：
1. 大容量 Cache（存储最近访问的data，尽量不从慢速内存读取数据）2.复杂的控制逻辑（预测数据需求，乱序执行指令，分支预测等）
CPU 通常只支持少量线程（比如超线程一般是2个），这是因为切换线程时，上下文切换的开销很大（需要保存和恢复线程状态）。所以倾向于让当前线程高效运行。

GPU: 